# LLM Voice

Library to reduce latency in voice generations from LLM chat completion streams.

## Installation and Setup

1. Install the package from PyPI with:

   ```bash
   pip install llm-voice
   ```

2. Copy the .env.example file to .env and fill in your OpenAI API key if you want to use OpenAI along with the model name for the Ollama/OpenAI model you want to use.
3. Take a look at one of the examples to start generating voice responses in realtime.

## Run From Source

```bash
pip install poetry
poetry install
```
